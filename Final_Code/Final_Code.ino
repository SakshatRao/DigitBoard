/**
* TinyML Trainer Example. 
* Version: v005
*
* This is an example generated by Tiny Motion Trainer 
* It is pre-filled with your trained model and your capture settings 
* 
* Required Libraries:
* - TensorFlow Lite for Microcontrollers (tested with v2.4-beta)
* - Arduino_LSM9DS1
*
* Usage:
* - Make sure the Arduino BLE 33 board is installed (tools->board->Board Manager) and connected
* - Make sure you have the required libraries installed
* - Build and upload the sketch
* - Keep the Arduino connected via USB and open the Serial Monitor (Tools->Serial Monitor)
* - The sketch will log out the label with the highest score once detected.
*
* This is meant as an example for you to develop your own code, and is not production ready.
*
**/

//==============================================================================
// Includes
//==============================================================================

#include <Arduino_LSM9DS1.h>
#include <TensorFlowLite.h>
#include <tensorflow/lite/micro/all_ops_resolver.h>
#include <tensorflow/lite/micro/micro_error_reporter.h>
#include <tensorflow/lite/micro/micro_interpreter.h>
#include <tensorflow/lite/schema/schema_generated.h>
#include <tensorflow/lite/version.h>
#include <Arduino_APDS9960.h>


//==============================================================================
// Your custom data / settings
// - Editing these is not recommended
//==============================================================================

// This is the model you trained in Tiny Motion Trainer, converted to 
// a C style byte array.
#include "binary_recognizer_model.h"

// Values from Tiny Motion Trainer
#define DIGITS_MOTION_THRESHOLD 0.093
#define DIGITS_CAPTURE_DELAY 500 // This is now in milliseconds
#define DIGITS_NUM_SAMPLES 150

// Array to map gesture index to a name
const char *DIGITS[] = {
    "0", "1"
};

#include "gesture_recognizer_model.h"

// Values from Tiny Motion Trainer
#define GESTURES_MOTION_THRESHOLD 0.09
#define GESTURES_CAPTURE_DELAY 1000 // This is now in milliseconds
#define GESTURES_NUM_SAMPLES 20

// Array to map gesture index to a name
const char *GESTURES[] = {
    "r", "l", "b", "s", "u", "d"
};


//==============================================================================
// Capture variables
//==============================================================================

#define NUM_DIGITS (sizeof(DIGITS) / sizeof(DIGITS[0]))
#define NUM_GESTURES (sizeof(GESTURES) / sizeof(GESTURES[0]))

bool DIGITS_isCapturing = false;
bool GESTURES_isCapturing = false;

// Num samples read from the IMU sensors
// "Full" by default to start in idle
int DIGITS_numSamplesRead = 0;

// Num samples read from the IMU sensors
// "Full" by default to start in idle
int GESTURES_numSamplesRead = 0;

#define LED_MOTION_DIGITS                     D6
#define LED_MOTION_GESTURES                   D3


//==============================================================================
// TensorFlow variables
//==============================================================================

// Global variables used for TensorFlow Lite (Micro)
tflite::MicroErrorReporter tflErrorReporter;

// Auto resolve all the TensorFlow Lite for MicroInterpreters ops, for reduced memory-footprint change this to only 
// include the op's you need.
tflite::AllOpsResolver tflOpsResolver;

// Setup model
const tflite::Model* DIGITS_tflModel = nullptr;
tflite::MicroInterpreter* DIGITS_tflInterpreter = nullptr;
TfLiteTensor* DIGITS_tflInputTensor = nullptr;
TfLiteTensor* DIGITS_tflOutputTensor = nullptr;

// Create a static memory buffer for TensorFlow Lite for MicroInterpreters, the size may need to
// be adjusted based on the model you are using
constexpr int DIGITS_tensorArenaSize = 8 * 1024;
byte DIGITS_tensorArena[DIGITS_tensorArenaSize];

// Setup model
const tflite::Model* GESTURES_tflModel = nullptr;
tflite::MicroInterpreter* GESTURES_tflInterpreter = nullptr;
TfLiteTensor* GESTURES_tflInputTensor = nullptr;
TfLiteTensor* GESTURES_tflOutputTensor = nullptr;

// Create a static memory buffer for TensorFlow Lite for MicroInterpreters, the size may need to
// be adjusted based on the model you are using
constexpr int GESTURES_tensorArenaSize = 8 * 1024;
byte GESTURES_tensorArena[GESTURES_tensorArenaSize];


//==============================================================================
// Piezo-electric Variables
//==============================================================================

void calibrate_piezo(void);

uint8_t piezo_avg_val, piezo_min_val, piezo_max_val;
uint8_t piezo_upper_thresh, piezo_lower_thresh;

#define STATUS_PRESSED                  1
#define STATUS_NOTPRESSED               0
uint8_t piezo_pressed_status;

#define LED_PIEZO                       D5

void calibrate_piezo(void)
{
  uint8_t piezo_calibration_iters = 20;
  int piezo_sum_val = 0;
  piezo_min_val = 255;
  piezo_max_val = 0;
  uint8_t piezo_val;
  for(int i = 0; i < piezo_calibration_iters; i++)
  {
    piezo_val = analogRead(A0);
    piezo_sum_val += piezo_val;
    if(piezo_val > piezo_max_val)
      piezo_max_val = piezo_val;
    if(piezo_val < piezo_min_val)
      piezo_min_val = piezo_val;
    delay(50);
  }
  piezo_avg_val = piezo_sum_val / piezo_calibration_iters;

  piezo_upper_thresh = piezo_avg_val + 2 * (piezo_max_val - piezo_avg_val);
  piezo_lower_thresh = piezo_avg_val - 2 * (piezo_avg_val - piezo_min_val);
}

int r, g, b, a;

#define LED_SERIAL                      LED_BUILTIN
#define LED_ILLUM                       D4
#define BUTTON_MODE                     D2




//==============================================================================
// Setup / Loop
//==============================================================================

void setup()
{
  pinMode(LED_PIEZO, OUTPUT);
  pinMode(LED_SERIAL, OUTPUT);
  pinMode(LED_MOTION_DIGITS, OUTPUT);
  pinMode(LED_MOTION_GESTURES, OUTPUT);
  pinMode(BUTTON_MODE, INPUT);
  pinMode(A0, INPUT);

  piezo_pressed_status = STATUS_NOTPRESSED;
  calibrate_piezo();
        
  Serial.begin(115200);

  // Initialize IMU sensors
  if (!IMU.begin())
  {
    while (1);
  }

  // Get the TFL representation of the model byte array
  DIGITS_tflModel = tflite::GetModel(binary_recognizer_model_weights);
  if (DIGITS_tflModel->version() != TFLITE_SCHEMA_VERSION)
  {
    while (1);
  }

  // Create an interpreter to run the model
  DIGITS_tflInterpreter = new tflite::MicroInterpreter(DIGITS_tflModel, tflOpsResolver, DIGITS_tensorArena, DIGITS_tensorArenaSize, &tflErrorReporter);

  // Allocate memory for the model's input and output tensors
  DIGITS_tflInterpreter->AllocateTensors();

  // Get pointers for the model's input and output tensors
  DIGITS_tflInputTensor = DIGITS_tflInterpreter->input(0);
  DIGITS_tflOutputTensor = DIGITS_tflInterpreter->output(0);

  // Get the TFL representation of the model byte array
  GESTURES_tflModel = tflite::GetModel(gesture_recognizer_model_weights);
  if (GESTURES_tflModel->version() != TFLITE_SCHEMA_VERSION)
  {
    while (1);
  }

  // Create an interpreter to run the model
  GESTURES_tflInterpreter = new tflite::MicroInterpreter(GESTURES_tflModel, tflOpsResolver, GESTURES_tensorArena, GESTURES_tensorArenaSize, &tflErrorReporter);

  // Allocate memory for the model's input and output tensors
  GESTURES_tflInterpreter->AllocateTensors();

  // Get pointers for the model's input and output tensors
  GESTURES_tflInputTensor = GESTURES_tflInterpreter->input(0);
  GESTURES_tflOutputTensor = GESTURES_tflInterpreter->output(0);

  if (!APDS.begin()) {
    Serial.println("Error initializing APDS9960 sensor.");
  }
}

void loop()
{
  if(Serial)
  {
    while(Serial.available())
      if(Serial.read() - 48 == 2)
        break;

    digitalWrite(LED_SERIAL, HIGH);
    
    while(Serial)
    {
      uint8_t mode = digitalRead(BUTTON_MODE);
      if(mode == 1)
      {
        
        // Variables to hold IMU data
        float aX, aY, aZ, gX, gY, gZ;
      
        // Wait for motion above the threshold setting
        if(!DIGITS_isCapturing)
        {
          if (IMU.accelerationAvailable() && IMU.gyroscopeAvailable())
          {
            IMU.readAcceleration(aX, aY, aZ);
            IMU.readGyroscope(gX, gY, gZ);
      
            // Sum absolute values
            float average = fabs(aX / 4.0) + fabs(aY / 4.0) + fabs(aZ / 4.0) + fabs(gX / 2000.0) + fabs(gY / 2000.0) + fabs(gZ / 2000.0);
            average /= 6.;
      
            // Above the threshold?
            if (average >= DIGITS_MOTION_THRESHOLD)
            {
              digitalWrite(LED_MOTION_DIGITS, HIGH);
              DIGITS_isCapturing = true;
              DIGITS_numSamplesRead = 0;
              break;
            }
          }
        }
      
        if(DIGITS_isCapturing)
        {
          // Check if both acceleration and gyroscope data is available
          if (IMU.accelerationAvailable() && IMU.gyroscopeAvailable())
          {
            // read the acceleration and gyroscope data
            IMU.readAcceleration(aX, aY, aZ);
            IMU.readGyroscope(gX, gY, gZ);
      
            // Normalize the IMU data between -1 to 1 and store in the model's
            // input tensor. Accelerometer data ranges between -4 and 4,
            // gyroscope data ranges between -2000 and 2000
            DIGITS_tflInputTensor->data.f[DIGITS_numSamplesRead * 6 + 0] = aX / 4.0;
            DIGITS_tflInputTensor->data.f[DIGITS_numSamplesRead * 6 + 1] = aY / 4.0;
            DIGITS_tflInputTensor->data.f[DIGITS_numSamplesRead * 6 + 2] = aZ / 4.0;
            DIGITS_tflInputTensor->data.f[DIGITS_numSamplesRead * 6 + 3] = gX / 2000.0;
            DIGITS_tflInputTensor->data.f[DIGITS_numSamplesRead * 6 + 4] = gY / 2000.0;
            DIGITS_tflInputTensor->data.f[DIGITS_numSamplesRead * 6 + 5] = gZ / 2000.0;
      
            DIGITS_numSamplesRead++;
      
            // Piezo-electric code
            if(piezo_pressed_status == STATUS_NOTPRESSED)
            {
              uint8_t piezo_val = analogRead(A0);
              if(piezo_val >= piezo_upper_thresh)
              {
                piezo_pressed_status = STATUS_PRESSED;
                digitalWrite(LED_PIEZO, HIGH);
              }
            }
      
            // Do we have the samples we need?
            if (DIGITS_numSamplesRead == DIGITS_NUM_SAMPLES)
            {  
              // Stop capturing
              DIGITS_isCapturing = false;
      
              if(piezo_pressed_status == STATUS_PRESSED)
              {
                // Run inference
                TfLiteStatus DIGITS_invokeStatus = DIGITS_tflInterpreter->Invoke();
                if (DIGITS_invokeStatus != kTfLiteOk)
                {
                  while (1);
                  return;
                }
        
                // Loop through the output tensor values from the model
                int maxIndex = 0;
                float maxValue = 0;
                for (int i = 0; i < NUM_DIGITS; i++)
                {
                  float _value = DIGITS_tflOutputTensor->data.f[i];
                  if(_value > maxValue)
                  {
                    maxValue = _value;
                    maxIndex = i;
                  }
                }
                
                Serial.println(DIGITS[maxIndex]);
      
                digitalWrite(LED_PIEZO, LOW);
                // Add delay to not double trigger
                delay(DIGITS_CAPTURE_DELAY);
                calibrate_piezo();
      
                piezo_pressed_status = STATUS_NOTPRESSED;
              }
              digitalWrite(LED_MOTION_DIGITS, LOW);
            }
          }
        }
        if(APDS.colorAvailable())
        {
          APDS.readColor(r, g, b, a);
          if(a < 5)
            digitalWrite(LED_ILLUM, HIGH);
          else
            digitalWrite(LED_ILLUM, LOW);
        }
      }
      else
      { 
        // Variables to hold IMU data
        float aX, aY, aZ, gX, gY, gZ;
      
        // Wait for motion above the threshold setting
        if(!GESTURES_isCapturing)
        {
          if (IMU.accelerationAvailable() && IMU.gyroscopeAvailable())
          {
            IMU.readAcceleration(aX, aY, aZ);
            IMU.readGyroscope(gX, gY, gZ);
      
            // Sum absolute values
            float average = fabs(aX / 4.0) + fabs(aY / 4.0) + fabs(aZ / 4.0) + fabs(gX / 2000.0) + fabs(gY / 2000.0) + fabs(gZ / 2000.0);
            average /= 6.;
      
            // Above the threshold?
            if (average >= GESTURES_MOTION_THRESHOLD)
            {
              digitalWrite(LED_MOTION_GESTURES, HIGH);
              GESTURES_isCapturing = true;
              GESTURES_numSamplesRead = 0;
              break;
            }
          }
        }
      
        if(GESTURES_isCapturing)
        {
          // Check if both acceleration and gyroscope data is available
          if (IMU.accelerationAvailable() && IMU.gyroscopeAvailable())
          {
            // read the acceleration and gyroscope data
            IMU.readAcceleration(aX, aY, aZ);
            IMU.readGyroscope(gX, gY, gZ);
      
            // Normalize the IMU data between -1 to 1 and store in the model's
            // input tensor. Accelerometer data ranges between -4 and 4,
            // gyroscope data ranges between -2000 and 2000
            GESTURES_tflInputTensor->data.f[GESTURES_numSamplesRead * 6 + 0] = aX / 4.0;
            GESTURES_tflInputTensor->data.f[GESTURES_numSamplesRead * 6 + 1] = aY / 4.0;
            GESTURES_tflInputTensor->data.f[GESTURES_numSamplesRead * 6 + 2] = aZ / 4.0;
            GESTURES_tflInputTensor->data.f[GESTURES_numSamplesRead * 6 + 3] = gX / 2000.0;
            GESTURES_tflInputTensor->data.f[GESTURES_numSamplesRead * 6 + 4] = gY / 2000.0;
            GESTURES_tflInputTensor->data.f[GESTURES_numSamplesRead * 6 + 5] = gZ / 2000.0;
      
            GESTURES_numSamplesRead++;
      
            // Do we have the samples we need?
            if (GESTURES_numSamplesRead == GESTURES_NUM_SAMPLES)
            {  
              // Stop capturing
              GESTURES_isCapturing = false;
      
              // Run inference
              TfLiteStatus GESTURES_invokeStatus = GESTURES_tflInterpreter->Invoke();
              if (GESTURES_invokeStatus != kTfLiteOk)
              {
                while (1);
                return;
              }
      
              // Loop through the output tensor values from the model
              int maxIndex = 0;
              float maxValue = 0;
              for (int i = 0; i < NUM_GESTURES; i++)
              {
                float _value = GESTURES_tflOutputTensor->data.f[i];
                if(_value > maxValue)
                {
                  maxValue = _value;
                  maxIndex = i;
                }
              }
              
              Serial.println(GESTURES[maxIndex]);
              
              // Add delay to not double trigger
              delay(GESTURES_CAPTURE_DELAY);
    
              digitalWrite(LED_MOTION_GESTURES, LOW);
            }
          }
        }
        if(APDS.colorAvailable())
        {
          APDS.readColor(r, g, b, a);
          if(a < 5)
            digitalWrite(LED_ILLUM, HIGH);
          else
            digitalWrite(LED_ILLUM, LOW);
        }
      }
    }
  }
  digitalWrite(LED_SERIAL, LOW);

  if(APDS.colorAvailable())
  {
    APDS.readColor(r, g, b, a);
    if(a < 5)
      digitalWrite(LED_ILLUM, HIGH);
    else
      digitalWrite(LED_ILLUM, LOW);
  }
}
